{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ef6c3ec157194946908db760941f9bb8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b9d53553da52458db77a4a32d9009f38","IPY_MODEL_3b9e8d8732254002a3c1c5719d418132","IPY_MODEL_1298db08f0154838bbef3ff6b68514e5"],"layout":"IPY_MODEL_08b81f61b85c47449781b01740371de3"}},"b9d53553da52458db77a4a32d9009f38":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91460ce95f56438dae180b72003d7b60","placeholder":"​","style":"IPY_MODEL_14a5b890a9cc4ee6999df60d9c53be70","value":"Map: 100%"}},"3b9e8d8732254002a3c1c5719d418132":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eda5a85740aa4cbe82a4f003d76ddb65","max":159571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_730e5d4b30e44e8a936296240ad87f12","value":159571}},"1298db08f0154838bbef3ff6b68514e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30d05b5ca79b437ea0c4b07c12ec81ca","placeholder":"​","style":"IPY_MODEL_9adeccff48bd4171bc4dbfadf7e86371","value":" 159571/159571 [03:56&lt;00:00, 745.58 examples/s]"}},"08b81f61b85c47449781b01740371de3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91460ce95f56438dae180b72003d7b60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14a5b890a9cc4ee6999df60d9c53be70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eda5a85740aa4cbe82a4f003d76ddb65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"730e5d4b30e44e8a936296240ad87f12":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"30d05b5ca79b437ea0c4b07c12ec81ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9adeccff48bd4171bc4dbfadf7e86371":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7182320,"sourceType":"datasetVersion","datasetId":4151559}],"dockerImageVersionId":30616,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install transformers[torch] accelerate==0.20.1","metadata":{"id":"pvUfCAcfImBJ","execution":{"iopub.status.busy":"2023-12-12T08:59:27.336291Z","iopub.execute_input":"2023-12-12T08:59:27.336685Z","iopub.status.idle":"2023-12-12T09:00:08.626466Z","shell.execute_reply.started":"2023-12-12T08:59:27.336657Z","shell.execute_reply":"2023-12-12T09:00:08.625253Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.35.2)\nCollecting accelerate==0.20.1\n  Obtaining dependency information for accelerate==0.20.1 from https://files.pythonhosted.org/packages/77/a8/af1e480814d0cccfe60def63471841a365dbd6f94e2d308d9bc1e3db2da2/accelerate-0.20.1-py3-none-any.whl.metadata\n  Downloading accelerate-0.20.1-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.20.1) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.20.1) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.20.1) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.20.1) (6.0.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.20.1) (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.19.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\nINFO: pip is looking at multiple versions of transformers[torch] to determine which version is compatible with other requirements. This could take a while.\nCollecting transformers[torch]\n  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/0f/12/d8e27a190ca67811f81deea3183b528d9169f10b74d827e0b9211520ecfa/transformers-4.36.0-py3-none-any.whl.metadata\n  Downloading transformers-4.36.0-py3-none-any.whl.metadata (126 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/92/ba/cfff7e01f7070d9fca3964bf42b2257b86964c3e6763b8d5435436cc1d77/transformers-4.35.1-py3-none-any.whl.metadata\n  Downloading transformers-4.35.1-py3-none-any.whl.metadata (123 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.1/123.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tokenizers<0.15,>=0.14 (from transformers[torch])\n  Obtaining dependency information for tokenizers<0.15,>=0.14 from https://files.pythonhosted.org/packages/a7/7b/c1f643eb086b6c5c33eef0c3752e37624bd23e4cbc9f1332748f1c6252d1/tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nCollecting transformers[torch]\n  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/9a/06/e4ec2a321e57c03b7e9345d709d554a52c33760e5015fdff0919d9459af0/transformers-4.35.0-py3-none-any.whl.metadata\n  Downloading transformers-4.35.0-py3-none-any.whl.metadata (123 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.1/123.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/c1/bd/f64d67df4d3b05a460f281defe830ffab6d7940b7ca98ec085e94e024781/transformers-4.34.1-py3-none-any.whl.metadata\n  Downloading transformers-4.34.1-py3-none-any.whl.metadata (121 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.5/121.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/1a/d1/3bba59606141ae808017f6fde91453882f931957f125009417b87a281067/transformers-4.34.0-py3-none-any.whl.metadata\n  Downloading transformers-4.34.0-py3-none-any.whl.metadata (121 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.5/121.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/98/46/f6a79f944d5c7763a9bc13b2aa6ac72daf43a6551f5fb03bccf0a9c2fec1/transformers-4.33.3-py3-none-any.whl.metadata\n  Downloading transformers-4.33.3-py3-none-any.whl.metadata (119 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers[torch])\n  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting transformers[torch]\n  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/1a/06/3817f9bb923437ead9a794f0ac0d03b8b5e0478ab112db4c413dd37c09da/transformers-4.33.2-py3-none-any.whl.metadata\n  Downloading transformers-4.33.2-py3-none-any.whl.metadata (119 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hINFO: pip is still looking at multiple versions of transformers[torch] to determine which version is compatible with other requirements. This could take a while.\n  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/13/30/54b59e73400df3de506ad8630284e9fd63f4b94f735423d55fc342181037/transformers-4.33.1-py3-none-any.whl.metadata\n  Downloading transformers-4.33.1-py3-none-any.whl.metadata (119 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/e1/9d/4d9fe5c3b820db10773392ac5f4a0c8dab668f70b245ce2ce09785166128/transformers-4.33.0-py3-none-any.whl.metadata\n  Downloading transformers-4.33.0-py3-none-any.whl.metadata (119 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/83/8d/f65f8138365462ace54458a9e164f4b28ce1141361970190eef36bdef986/transformers-4.32.1-py3-none-any.whl.metadata\n  Downloading transformers-4.32.1-py3-none-any.whl.metadata (118 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/ae/95/283a1c004430bd2a9425d6937fc545dd49a4e4592feb76be0299a14e2378/transformers-4.32.0-py3-none-any.whl.metadata\n  Downloading transformers-4.32.0-py3-none-any.whl.metadata (118 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/21/02/ae8e595f45b6c8edee07913892b3b41f5f5f273962ad98851dc6a564bbb9/transformers-4.31.0-py3-none-any.whl.metadata\n  Downloading transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/5b/0b/e45d26ccd28568013523e04f325432ea88a442b4e3020b757cf4361f0120/transformers-4.30.2-py3-none-any.whl.metadata\n  Downloading transformers-4.30.2-py3-none-any.whl.metadata (113 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/b8/df/b01b5e67cde3883757c9212455cbb9169385dcab5858b7172199126b756d/transformers-4.30.1-py3-none-any.whl.metadata\n  Downloading transformers-4.30.1-py3-none-any.whl.metadata (113 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/e2/72/1af3d38e98fdcceb3876de4567ac395a66c26976e259fe2d46266e052d61/transformers-4.30.0-py3-none-any.whl.metadata\n  Downloading transformers-4.30.0-py3-none-any.whl.metadata (113 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Obtaining dependency information for transformers[torch] from https://files.pythonhosted.org/packages/17/aa/a89864288afe45abe1ab79f002140a20348140e86836d96096d8f8a3bac0/transformers-4.29.2-py3-none-any.whl.metadata\n  Downloading transformers-4.29.2-py3-none-any.whl.metadata (112 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.12.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.20.1) (3.0.9)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.1) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.1) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.1) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2023.11.17)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->accelerate==0.20.1) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->accelerate==0.20.1) (1.3.0)\nDownloading accelerate-0.20.1-py3-none-any.whl (227 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.5/227.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers, transformers, accelerate\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.15.0\n    Uninstalling tokenizers-0.15.0:\n      Successfully uninstalled tokenizers-0.15.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.35.2\n    Uninstalling transformers-4.35.2:\n      Successfully uninstalled transformers-4.35.2\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.25.0\n    Uninstalling accelerate-0.25.0:\n      Successfully uninstalled accelerate-0.25.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.14.3 requires transformers>=4.33.1, but you have transformers 4.29.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-0.20.1 tokenizers-0.13.3 transformers-4.29.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip show accelerate","metadata":{"execution":{"iopub.status.busy":"2023-12-12T09:00:13.359160Z","iopub.execute_input":"2023-12-12T09:00:13.359573Z","iopub.status.idle":"2023-12-12T09:00:25.234968Z","shell.execute_reply.started":"2023-12-12T09:00:13.359537Z","shell.execute_reply":"2023-12-12T09:00:25.233693Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Name: accelerate\nVersion: 0.20.1\nSummary: Accelerate\nHome-page: https://github.com/huggingface/accelerate\nAuthor: The HuggingFace team\nAuthor-email: sylvain@huggingface.co\nLicense: Apache\nLocation: /opt/conda/lib/python3.10/site-packages\nRequires: numpy, packaging, psutil, pyyaml, torch\nRequired-by: catalyst\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install evaluate","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install --upgrade datasets","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom datasets import Dataset,DatasetDict\nfrom transformers import DataCollatorWithPadding\nimport evaluate\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom transformers import AutoModelForSequenceClassification\nfrom transformers import TrainingArguments\nfrom transformers import AutoTokenizer\nfrom transformers import Trainer, TrainingArguments\nimport pickle\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"id":"A8onnvLeFQO5","execution":{"iopub.status.busy":"2023-12-12T09:51:26.011575Z","iopub.execute_input":"2023-12-12T09:51:26.011973Z","iopub.status.idle":"2023-12-12T09:51:26.022650Z","shell.execute_reply.started":"2023-12-12T09:51:26.011946Z","shell.execute_reply":"2023-12-12T09:51:26.021277Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"","metadata":{"execution":{"iopub.status.busy":"2023-12-12T09:51:28.880779Z","iopub.execute_input":"2023-12-12T09:51:28.881549Z","iopub.status.idle":"2023-12-12T09:51:28.887151Z","shell.execute_reply.started":"2023-12-12T09:51:28.881518Z","shell.execute_reply":"2023-12-12T09:51:28.885835Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/dataset-dina/train.csv\")","metadata":{"id":"IUazqmyKHXCP","execution":{"iopub.status.busy":"2023-12-12T09:51:34.630032Z","iopub.execute_input":"2023-12-12T09:51:34.630786Z","iopub.status.idle":"2023-12-12T09:51:35.655907Z","shell.execute_reply.started":"2023-12-12T09:51:34.630749Z","shell.execute_reply":"2023-12-12T09:51:35.654283Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8bM0XHCdIzx9","outputId":"66b0221e-f5b7-4eef-cc0b-7b111c030eb9","execution":{"iopub.status.busy":"2023-12-12T09:51:37.010051Z","iopub.execute_input":"2023-12-12T09:51:37.010490Z","iopub.status.idle":"2023-12-12T09:51:37.065980Z","shell.execute_reply.started":"2023-12-12T09:51:37.010455Z","shell.execute_reply":"2023-12-12T09:51:37.064818Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 159571 entries, 0 to 159570\nData columns (total 8 columns):\n #   Column         Non-Null Count   Dtype \n---  ------         --------------   ----- \n 0   id             159571 non-null  object\n 1   comment_text   159571 non-null  object\n 2   toxic          159571 non-null  int64 \n 3   severe_toxic   159571 non-null  int64 \n 4   obscene        159571 non-null  int64 \n 5   threat         159571 non-null  int64 \n 6   insult         159571 non-null  int64 \n 7   identity_hate  159571 non-null  int64 \ndtypes: int64(6), object(2)\nmemory usage: 9.7+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"data.head(5)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"vv23KS0iKYnb","outputId":"3c4b60c4-a850-45b1-a3dc-27f4cc774184","execution":{"iopub.status.busy":"2023-12-12T09:51:39.217868Z","iopub.execute_input":"2023-12-12T09:51:39.218619Z","iopub.status.idle":"2023-12-12T09:51:39.236372Z","shell.execute_reply.started":"2023-12-12T09:51:39.218583Z","shell.execute_reply":"2023-12-12T09:51:39.235475Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"                 id                                       comment_text  toxic  \\\n0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \n0             0        0       0       0              0  \n1             0        0       0       0              0  \n2             0        0       0       0              0  \n3             0        0       0       0              0  \n4             0        0       0       0              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_toxic = data.copy()\ndf_toxic['is_toxic'] = df_toxic[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].apply(lambda row: any(row), axis=1).astype(int)\ndf_toxic = df_toxic.drop(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'], axis=1)","metadata":{"id":"EYkTr1-gKkqy","execution":{"iopub.status.busy":"2023-12-12T09:51:41.002273Z","iopub.execute_input":"2023-12-12T09:51:41.003206Z","iopub.status.idle":"2023-12-12T09:51:42.477903Z","shell.execute_reply.started":"2023-12-12T09:51:41.003170Z","shell.execute_reply":"2023-12-12T09:51:42.476512Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"df_toxic","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"_2hDh4a_Ksty","outputId":"e70c56be-f6f3-4d36-bfce-82a52ad69db3","execution":{"iopub.status.busy":"2023-12-12T09:51:43.909849Z","iopub.execute_input":"2023-12-12T09:51:43.910592Z","iopub.status.idle":"2023-12-12T09:51:43.928598Z","shell.execute_reply.started":"2023-12-12T09:51:43.910558Z","shell.execute_reply":"2023-12-12T09:51:43.925709Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"                      id                                       comment_text  \\\n0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n...                  ...                                                ...   \n159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n\n        is_toxic  \n0              0  \n1              0  \n2              0  \n3              0  \n4              0  \n...          ...  \n159566         0  \n159567         0  \n159568         0  \n159569         0  \n159570         0  \n\n[159571 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>is_toxic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>159566</th>\n      <td>ffe987279560d7ff</td>\n      <td>\":::::And for the second time of asking, when ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159567</th>\n      <td>ffea4adeee384e90</td>\n      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159568</th>\n      <td>ffee36eab5c267c9</td>\n      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159569</th>\n      <td>fff125370e4aaaf3</td>\n      <td>And it looks like it was actually you who put ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159570</th>\n      <td>fff46fc426af1f9a</td>\n      <td>\"\\nAnd ... I really don't think you understand...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>159571 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_toxic = df_toxic.drop('id', axis=1)","metadata":{"id":"V59UWtKRKygC","execution":{"iopub.status.busy":"2023-12-12T09:51:46.149222Z","iopub.execute_input":"2023-12-12T09:51:46.150003Z","iopub.status.idle":"2023-12-12T09:51:46.162237Z","shell.execute_reply.started":"2023-12-12T09:51:46.149959Z","shell.execute_reply":"2023-12-12T09:51:46.161182Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"df_toxic.head(5)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"z4YuSzizLF8C","outputId":"d5b9aaca-26da-45a1-bd2b-e963df171f14","execution":{"iopub.status.busy":"2023-12-12T09:51:47.944377Z","iopub.execute_input":"2023-12-12T09:51:47.945108Z","iopub.status.idle":"2023-12-12T09:51:47.957142Z","shell.execute_reply.started":"2023-12-12T09:51:47.945069Z","shell.execute_reply":"2023-12-12T09:51:47.955869Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"                                        comment_text  is_toxic\n0  Explanation\\nWhy the edits made under my usern...         0\n1  D'aww! He matches this background colour I'm s...         0\n2  Hey man, I'm really not trying to edit war. It...         0\n3  \"\\nMore\\nI can't make any real suggestions on ...         0\n4  You, sir, are my hero. Any chance you remember...         0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_text</th>\n      <th>is_toxic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_toxic['is_toxic'].value_counts()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e27un2LdLOgP","outputId":"5ad903cb-ba5e-45cf-d3b3-944a33cec5aa","execution":{"iopub.status.busy":"2023-12-12T09:51:50.365808Z","iopub.execute_input":"2023-12-12T09:51:50.366213Z","iopub.status.idle":"2023-12-12T09:51:50.377554Z","shell.execute_reply.started":"2023-12-12T09:51:50.366181Z","shell.execute_reply":"2023-12-12T09:51:50.376598Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"is_toxic\n0    143346\n1     16225\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df_toxic_balanced = pd.concat([\n    df_toxic[df_toxic['is_toxic'] == 0].sample(2000, random_state=42),\n    df_toxic[df_toxic['is_toxic'] == 1].sample(2000, random_state=42)\n])\n\ndf_toxic_balanced = df_toxic_balanced.sample(frac=1, random_state=42)\n\nprint(df_toxic_balanced['is_toxic'].value_counts())","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zfXNnu_nJI2e","outputId":"84835afd-3a63-4914-e37e-484dbef78b04","execution":{"iopub.status.busy":"2023-12-12T09:51:52.234497Z","iopub.execute_input":"2023-12-12T09:51:52.234903Z","iopub.status.idle":"2023-12-12T09:51:52.273768Z","shell.execute_reply.started":"2023-12-12T09:51:52.234872Z","shell.execute_reply":"2023-12-12T09:51:52.272641Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"is_toxic\n0    2000\n1    2000\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"df_toxic_balanced.dtypes","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZV0SzxGrhXdv","outputId":"53cf5b2a-707d-4f31-ec2c-9a862479dd62","execution":{"iopub.status.busy":"2023-12-12T09:51:55.115252Z","iopub.execute_input":"2023-12-12T09:51:55.115661Z","iopub.status.idle":"2023-12-12T09:51:55.125486Z","shell.execute_reply.started":"2023-12-12T09:51:55.115619Z","shell.execute_reply":"2023-12-12T09:51:55.124208Z"},"trusted":true},"execution_count":77,"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"comment_text    object\nis_toxic         int64\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"df_toxic_balanced = df_toxic_balanced.rename(columns={'is_toxic': 'label'})\ndf_toxic_balanced['label'] = df_toxic_balanced['label'].astype(float)","metadata":{"id":"qDOWaFa3hQZZ","execution":{"iopub.status.busy":"2023-12-12T09:51:57.522264Z","iopub.execute_input":"2023-12-12T09:51:57.523115Z","iopub.status.idle":"2023-12-12T09:51:57.531582Z","shell.execute_reply.started":"2023-12-12T09:51:57.523078Z","shell.execute_reply":"2023-12-12T09:51:57.530495Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"df_toxic_balanced.dtypes","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wAhVroXChdKf","outputId":"858cfc57-1e38-4e5a-e155-ca35e4fa9848","execution":{"iopub.status.busy":"2023-12-12T09:52:03.632691Z","iopub.execute_input":"2023-12-12T09:52:03.633671Z","iopub.status.idle":"2023-12-12T09:52:03.642370Z","shell.execute_reply.started":"2023-12-12T09:52:03.633629Z","shell.execute_reply":"2023-12-12T09:52:03.641327Z"},"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"comment_text     object\nlabel           float64\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"ds = Dataset.from_pandas(df_toxic_balanced)","metadata":{"id":"G8OVitvDdSH5","execution":{"iopub.status.busy":"2023-12-12T09:52:05.865477Z","iopub.execute_input":"2023-12-12T09:52:05.865859Z","iopub.status.idle":"2023-12-12T09:52:05.882977Z","shell.execute_reply.started":"2023-12-12T09:52:05.865831Z","shell.execute_reply":"2023-12-12T09:52:05.882085Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if _pandas_api.is_sparse(col):\n","output_type":"stream"}]},{"cell_type":"code","source":"ds","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HzhVgsxKdghx","outputId":"04465a74-78fb-4148-c037-b779a5542dda","execution":{"iopub.status.busy":"2023-12-12T09:52:07.803974Z","iopub.execute_input":"2023-12-12T09:52:07.804335Z","iopub.status.idle":"2023-12-12T09:52:07.811981Z","shell.execute_reply.started":"2023-12-12T09:52:07.804305Z","shell.execute_reply":"2023-12-12T09:52:07.810712Z"},"trusted":true},"execution_count":81,"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['comment_text', 'label', '__index_level_0__'],\n    num_rows: 4000\n})"},"metadata":{}}]},{"cell_type":"code","source":"pretrained_model = 'distilbert-base-cased'","metadata":{"id":"PPQ4WAPTdj_-","execution":{"iopub.status.busy":"2023-12-12T09:52:10.598814Z","iopub.execute_input":"2023-12-12T09:52:10.599171Z","iopub.status.idle":"2023-12-12T09:52:10.604905Z","shell.execute_reply.started":"2023-12-12T09:52:10.599143Z","shell.execute_reply":"2023-12-12T09:52:10.603401Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(pretrained_model, use_fast =True) # False","metadata":{"id":"2tGedA_WdnR3","execution":{"iopub.status.busy":"2023-12-12T09:52:31.599296Z","iopub.execute_input":"2023-12-12T09:52:31.600137Z","iopub.status.idle":"2023-12-12T09:52:31.713661Z","shell.execute_reply.started":"2023-12-12T09:52:31.600105Z","shell.execute_reply":"2023-12-12T09:52:31.712636Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"def preprocess(x):\n    return tokenizer(x[\"comment_text\"], truncation=True, max_length=128)","metadata":{"id":"6jUPPPKleKA2","execution":{"iopub.status.busy":"2023-12-12T10:04:57.384556Z","iopub.execute_input":"2023-12-12T10:04:57.384971Z","iopub.status.idle":"2023-12-12T10:04:57.391528Z","shell.execute_reply.started":"2023-12-12T10:04:57.384942Z","shell.execute_reply":"2023-12-12T10:04:57.390461Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"tok_ds = ds.map(preprocess, batched=True)\ntok_ds","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":118,"referenced_widgets":["ef6c3ec157194946908db760941f9bb8","b9d53553da52458db77a4a32d9009f38","3b9e8d8732254002a3c1c5719d418132","1298db08f0154838bbef3ff6b68514e5","08b81f61b85c47449781b01740371de3","91460ce95f56438dae180b72003d7b60","14a5b890a9cc4ee6999df60d9c53be70","eda5a85740aa4cbe82a4f003d76ddb65","730e5d4b30e44e8a936296240ad87f12","30d05b5ca79b437ea0c4b07c12ec81ca","9adeccff48bd4171bc4dbfadf7e86371"]},"id":"RbxHE8ieeQtV","outputId":"6d021eae-67a0-403f-afde-4243885bcbaa","execution":{"iopub.status.busy":"2023-12-12T10:05:00.378960Z","iopub.execute_input":"2023-12-12T10:05:00.379333Z","iopub.status.idle":"2023-12-12T10:05:00.935945Z","shell.execute_reply.started":"2023-12-12T10:05:00.379301Z","shell.execute_reply":"2023-12-12T10:05:00.934930Z"},"trusted":true},"execution_count":110,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4ead7f0782b44bc8d5caf5741b36201"}},"metadata":{}},{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['comment_text', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n    num_rows: 4000\n})"},"metadata":{}}]},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding='max_length')","metadata":{"id":"0SQ4PQTRfTSh","execution":{"iopub.status.busy":"2023-12-12T10:05:03.485679Z","iopub.execute_input":"2023-12-12T10:05:03.486078Z","iopub.status.idle":"2023-12-12T10:05:03.493145Z","shell.execute_reply.started":"2023-12-12T10:05:03.486046Z","shell.execute_reply":"2023-12-12T10:05:03.491968Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"dataset = tok_ds.train_test_split(test_size=0.3)","metadata":{"id":"zzsEGbHjfmVk","execution":{"iopub.status.busy":"2023-12-12T10:05:05.588917Z","iopub.execute_input":"2023-12-12T10:05:05.589300Z","iopub.status.idle":"2023-12-12T10:05:05.604973Z","shell.execute_reply.started":"2023-12-12T10:05:05.589269Z","shell.execute_reply":"2023-12-12T10:05:05.603999Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lfNSj1ABfoXT","outputId":"2f03d03b-240b-4865-d357-2dd40aa8afbb","execution":{"iopub.status.busy":"2023-12-12T10:05:08.861053Z","iopub.execute_input":"2023-12-12T10:05:08.861438Z","iopub.status.idle":"2023-12-12T10:05:08.869747Z","shell.execute_reply.started":"2023-12-12T10:05:08.861395Z","shell.execute_reply":"2023-12-12T10:05:08.868613Z"},"trusted":true},"execution_count":113,"outputs":[{"execution_count":113,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['comment_text', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n        num_rows: 2800\n    })\n    test: Dataset({\n        features: ['comment_text', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n        num_rows: 1200\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"tok_train_dataset = dataset[\"train\"]\ntok_test_dataset = dataset[\"test\"]","metadata":{"id":"8uyFGmv0frI0","execution":{"iopub.status.busy":"2023-12-12T10:05:11.235137Z","iopub.execute_input":"2023-12-12T10:05:11.235524Z","iopub.status.idle":"2023-12-12T10:05:11.241762Z","shell.execute_reply.started":"2023-12-12T10:05:11.235493Z","shell.execute_reply":"2023-12-12T10:05:11.240559Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"accuracy = evaluate.load(\"accuracy\")","metadata":{"id":"R4ylSRkmf9Yf","execution":{"iopub.status.busy":"2023-12-12T10:05:13.299828Z","iopub.execute_input":"2023-12-12T10:05:13.300277Z","iopub.status.idle":"2023-12-12T10:05:13.693609Z","shell.execute_reply.started":"2023-12-12T10:05:13.300222Z","shell.execute_reply":"2023-12-12T10:05:13.692461Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return accuracy.compute(predictions=predictions, references=labels)","metadata":{"id":"unKGQB4qgHd4","execution":{"iopub.status.busy":"2023-12-12T10:05:15.474577Z","iopub.execute_input":"2023-12-12T10:05:15.475580Z","iopub.status.idle":"2023-12-12T10:05:15.481379Z","shell.execute_reply.started":"2023-12-12T10:05:15.475542Z","shell.execute_reply":"2023-12-12T10:05:15.480242Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(pred):\n    labels = pred.label_ids.float()\n    preds = pred.predictions.argmax(-1).float()\n    f1 = f1_score(labels, preds, average=\"weighted\")\n    acc = accuracy_score(labels, preds)\n    return {\"accuracy\": acc, \"f1\": f1}","metadata":{"id":"nLI-BwNUgKe4","execution":{"iopub.status.busy":"2023-12-12T10:05:17.696389Z","iopub.execute_input":"2023-12-12T10:05:17.696799Z","iopub.status.idle":"2023-12-12T10:05:17.704993Z","shell.execute_reply.started":"2023-12-12T10:05:17.696770Z","shell.execute_reply":"2023-12-12T10:05:17.703801Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(pretrained_model, num_labels=1, output_attentions=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xyx9DB6-ZhLQ","outputId":"921b583b-6cf1-4761-8c78-02f5ce72ed9d","execution":{"iopub.status.busy":"2023-12-12T10:05:21.728833Z","iopub.execute_input":"2023-12-12T10:05:21.729223Z","iopub.status.idle":"2023-12-12T10:05:22.334195Z","shell.execute_reply.started":"2023-12-12T10:05:21.729193Z","shell.execute_reply":"2023-12-12T10:05:22.333121Z"},"trusted":true},"execution_count":118,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./results\",\n    learning_rate=2e-5,\n    warmup_ratio=0.1,\n    lr_scheduler_type=\"cosine\",\n    fp16=True,\n    # gradient_checkpointing=True, #according to Bing Chat this will do a trade-off between speed and memory usage, but distilbert doesn't support it\n    #per_device_train_batch_size=2,#16 is better, but requires more RAM\n    #per_device_eval_batch_size=2, #16 is better, but requires more RAM\n    num_train_epochs=2,\n    weight_decay=0.01,\n    #evaluation_strategy=\"epoch\",\n    #save_strategy=\"epoch\",\n    #load_best_model_at_end=True\n)","metadata":{"id":"-ygf7Nahgbwk","execution":{"iopub.status.busy":"2023-12-12T10:05:24.458559Z","iopub.execute_input":"2023-12-12T10:05:24.459450Z","iopub.status.idle":"2023-12-12T10:05:24.471052Z","shell.execute_reply.started":"2023-12-12T10:05:24.459400Z","shell.execute_reply":"2023-12-12T10:05:24.469929Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tok_train_dataset,\n    eval_dataset=tok_test_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"9tN3brjKSfxY","outputId":"1cd24289-485d-4465-aedf-d1aee4a291e3","execution":{"iopub.status.busy":"2023-12-12T10:05:27.224856Z","iopub.execute_input":"2023-12-12T10:05:27.225541Z","iopub.status.idle":"2023-12-12T10:07:02.405510Z","shell.execute_reply.started":"2023-12-12T10:05:27.225505Z","shell.execute_reply":"2023-12-12T10:07:02.404547Z"},"trusted":true},"execution_count":120,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='350' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [350/350 01:34, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":120,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=350, training_loss=0.08759590148925782, metrics={'train_runtime': 95.0849, 'train_samples_per_second': 58.895, 'train_steps_per_second': 3.681, 'total_flos': 741804203212800.0, 'train_loss': 0.08759590148925782, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model(\"comments_model_v2\")","metadata":{"execution":{"iopub.status.busy":"2023-12-12T10:07:11.966501Z","iopub.execute_input":"2023-12-12T10:07:11.967622Z","iopub.status.idle":"2023-12-12T10:07:12.413322Z","shell.execute_reply.started":"2023-12-12T10:07:11.967586Z","shell.execute_reply":"2023-12-12T10:07:12.412113Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"model_save_path = '/kaggle/working/comments_model_v2.pkl'\n\nwith open(model_save_path, 'wb') as model_file:\n    pickle.dump(model, model_file)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T10:07:21.772526Z","iopub.execute_input":"2023-12-12T10:07:21.773274Z","iopub.status.idle":"2023-12-12T10:07:22.217862Z","shell.execute_reply.started":"2023-12-12T10:07:21.773233Z","shell.execute_reply":"2023-12-12T10:07:22.216487Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"model_pickle_path = '/kaggle/working/comments_model_v2.pkl'\n\nwith open(model_pickle_path, 'rb') as model_file:\n    model = pickle.load(model_file)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T10:07:30.917952Z","iopub.execute_input":"2023-12-12T10:07:30.918698Z","iopub.status.idle":"2023-12-12T10:07:31.214701Z","shell.execute_reply.started":"2023-12-12T10:07:30.918666Z","shell.execute_reply":"2023-12-12T10:07:31.213462Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, AutoTokenizer, TextClassificationPipeline\n \nmodel_path = \"/kaggle/working/comments_model_v2\"\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path)\n \npipeline =  TextClassificationPipeline(model=model, tokenizer=tokenizer)\nprint(pipeline(\"D'aww! He matches this background colour I'm seemingly stuck with. Thanks.\"))","metadata":{"execution":{"iopub.status.busy":"2023-12-12T10:07:51.312626Z","iopub.execute_input":"2023-12-12T10:07:51.313029Z","iopub.status.idle":"2023-12-12T10:07:51.968070Z","shell.execute_reply.started":"2023-12-12T10:07:51.313001Z","shell.execute_reply":"2023-12-12T10:07:51.965486Z"},"trusted":true},"execution_count":125,"outputs":[{"name":"stdout","text":"[{'label': 'LABEL_0', 'score': 0.5156227946281433}]\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\n\nconfig_path = \"/kaggle/working/comments_model/config.json\"\n\nwith open(config_path, 'r') as config_file:\n    config = json.load(config_file)\n\nconfig\n","metadata":{"execution":{"iopub.status.busy":"2023-12-12T09:36:56.848527Z","iopub.execute_input":"2023-12-12T09:36:56.849396Z","iopub.status.idle":"2023-12-12T09:36:56.861129Z","shell.execute_reply.started":"2023-12-12T09:36:56.849354Z","shell.execute_reply":"2023-12-12T09:36:56.859852Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"{'_name_or_path': 'distilbert-base-cased',\n 'activation': 'gelu',\n 'architectures': ['DistilBertForSequenceClassification'],\n 'attention_dropout': 0.1,\n 'dim': 768,\n 'dropout': 0.1,\n 'hidden_dim': 3072,\n 'id2label': {'0': 'LABEL_0'},\n 'initializer_range': 0.02,\n 'label2id': {'LABEL_0': 0},\n 'max_position_embeddings': 512,\n 'model_type': 'distilbert',\n 'n_heads': 12,\n 'n_layers': 6,\n 'output_attentions': True,\n 'output_past': True,\n 'pad_token_id': 0,\n 'problem_type': 'regression',\n 'qa_dropout': 0.1,\n 'seq_classif_dropout': 0.2,\n 'sinusoidal_pos_embds': False,\n 'tie_weights_': True,\n 'torch_dtype': 'float32',\n 'transformers_version': '4.29.2',\n 'vocab_size': 28996}"},"metadata":{}}]}]}