{"cells":[{"cell_type":"markdown","metadata":{},"source":["# NLP - Toxic Comments Classifier (Report)\n","\n","Team Number: 6\n","<br/>\n","Team Members: Dina Boshnaq, Iris Loret, Ingrid Hansen\n","<br/>\n","Streamlit app URL: https://toxiccomments.streamlit.app/\n","\n","## Introduction\n","For this assignment we are doing classification of comments to check if they're toxic or not. The dataset used is the Toxic Comment Classification dataset from Kaggle. We will be doing single label classification (toxic or not toxic) instead of multi label classification. We are using a Transformer model from Hugging Face, specifically the DistilBERT base model (uncased). We are doing transfer learning by using the pre-trained tokenizer from the language model (DistilBERT) to initialize a new tokenizer and then build our own model based on it.\n","We split our dataset then train the model, and finally make predictions on text that we pass to the model.\n","\n","We are running our code on Kaggle since it has a closer connection to the data source so it uses less memory. Initially we had tried Colab but we were using too much memory so we switched to Kaggle."]},{"cell_type":"markdown","metadata":{},"source":["## EDA\n","We start off by downloading the dataset from Kaggle, we will be using the train.csv file to train our data. We load the data file in a dataset on Kaggle. Then we load that file as a pandas dataframe in our code.\n","\n","We did a simple EDA on the data where we checked the different columns and their datatypes.\n","\n","<img src=\"reportImages/info.jpg\" width=\"400\"/>\n","\n","We have a comment_text column with the comments, and 6 different types of toxic comments. But since we're only doing single label classification, we want to have one column as the label to predict. We make one column called is_toxic. That's why for each row, we check if any of the 6 types of toxic comments are set to 1 (1 meaning it is of that type of toxicity, 0 meaning it's not). If at least one of them is set to 1, we set the value in is_toxic to 1. If none of them are valued 1, we set it to 0. Then we drop the 6 columns, keeping only comment_text and is_toxic. We also dropped the id column since there's no use for it.\n","\n","When checking the value counts of the is_toxic column, the 0 value had 143346 entries while the 1 value had 16225. This causes an imbalance in the data, and it's also too much data since we were still testing it. Therefore, we undersampled and balanced the data out by taking only 2000 samples from each (the 0 entries, and the 1 entries). This will make training the model faster and easier. If we can get this to run then we know it's working and we can increase the number of samples to make a better model.\n","\n","An issue that was encountered later on when trying to train the model is that it wasn't seeing the is_toxic column as the target label column, so we had to rename it to \"label\" per the documentation.\n","\n","Up to this point, the data type of label is integer and it's either 0 or 1. But this isn't enough to identify the labels, especially since we will be assigning the number of labels to 2 when making the model. The model configurations, especially the num_labels parameter, need to match the number of unique labels used during training. id2label and label2id should be correctly configured in the config.json file in the model directory.\n","If the original labels are numeric (0 and 1), the model might expect a mapping like id2label = {0: '0', 1: '1'} and label2id = {'0': 0, '1': 1}. However, if we use string labels, the mapping would be more intuitive: id2label = {'Not Toxic': 0, 'Toxic': 1} and label2id = {0: 'Not Toxic', 1: 'Toxic'}. We tried both and the second approach worked where we first map 0 to \"Not Toxic\" and 1 to \"Toxic\", then encode the labels:\n","\n","id2label = {0: \"Not Toxic\", 1: \"Toxic\"}\n","label2id = {\"Not Toxic\": 0, \"Toxic\": 1}\n","df_toxic_balanced[\"label\"] = df_toxic_balanced[\"label\"].apply(lambda x: label2id[x])\n","\n","This will result in the configuration in the config.json (which will be produced later on when making the model) to be correct later on where we'd have the 2 labels and the correct problem type \"single label classification\".\n","\n","The final correct config.json:\n","\n","<img src=\"reportImages/rightConfig.jpg\" width=\"400\"/>\n","\n","The initial wrong config.json:\n","\n","<img src=\"reportImages/wrongConfig.jpg\" width=\"400\"/>\n","\n","\n","We then make the hugging face dataset from our dataframe in order to apply tokenization on it."]},{"cell_type":"markdown","metadata":{},"source":["## Tokenizing the data\n","\n","The pre-trained transformer model we're using is a distilled version of the BERT base model (DistilBERT), specifically the uncased one (case insensitive).\n","We decided to try this one first since it's smaller and faster than BERT but based on it. It is self-supervised and uses Masked language modeling (MLM) which is in a way good since it can learn in a bidirectional representation of the sentence. It should get the job done, but of course, there are other transformer models out there that are more accurate in classifying comments based on toxicity, however they're bigger and will take a longer time in training. Since we're testing things out first, this model suffices.\n","\n","A tokenizer is needed in order to convert raw input (sentences) into smaller units such as words, this will help the ML models to understand and process the input. \n","We initialize the tokenizer to be used using the AutoTokenizer class from Hugging face transformers library. This class will help us load a pre-trained tokenizer for our model from the pre-trained DistilBERT Uncased model. We set the use_fast parameter to True, this will enable the use of a fast tokenizer.\n","\n","A function named \"preprocess\" is created to map the tokenizer to the dataset, specifically to the column \"comment_text\" which contains the input text to be analyzed. It then applies the tokenizer on each input sentence. The tokenizer is configured with the parameters truncation=True and max_length=128, indicating that it should truncate sequences longer than 128 tokens while ensuring that sequences are not longer than this maximum length. This will ensure that the input sequences have a consistent length which makes the processing by the model more efficient. So in summary, through this function we will prepare the dataset for further processing by transforming the raw text in the \"comment_text\" column into tokenized sequences suitable for input to natural language processing models.\n","\n","We apply the preprocess function on our dataset. The mapping function will be applied in batches rather than individually for each sample (batched=True). Then, a DataCollatorWithPadding object (DataCollatorWithPadding is a class in the Hugging Face library) is created to form these batches of the data. We are using the tokenizer we made earlier and a padding strategy 'max_length', which means that the sequences will be padded to the maximum length in the batch. The data collator will create uniform batch sizes, which allow efficient parallel processing in deep learning frameworks, by using Truncation and Padding. These are 2 different ways of achieving uniform batch sizes.\n","It trunctuates the sequences which exceed the maximum length, and pads the sequences which are less than the maximum length. The maximum length is determined by the maximum length of the input sequences after they have been tokenized by the tokenizer. Truncation involves shortening a sequence by removing tokens from the end. While padding involves adding special tokens (usually zeros) to the end of a sequence to make it equal in length to the maximum sequence length within a batch."]},{"cell_type":"markdown","metadata":{},"source":["## Creating Train and Test set\n","\n","We split the tokenized dataset into training and test sets, %70 for training, %30 for testing. Our dataset is now the following:\n","\n","<img src=\"reportImages/datasetSplit.jpg\"/>\n","\n","We define the training set and testing set individually so we can pass them to model later. They are called tok_train_dataset and tok_test_dataset."]},{"cell_type":"markdown","metadata":{},"source":["## Creating an Evaluation Metric\n","\n","We use the library called \"Evaluate\" for evaluating our model. It is a library with a wide range of evaluation tools. There are 3 types of evaluations in it, one of them is \"Metric\" which we will be using. It measures the performance of a model on a given dataset, usually by comparing the model's predictions to some ground truth labels. We will be using an \"Accuracy\" metric from this type. According to the documentation on the Hugging Face website: Accuracy is the proportion of correct predictions among the total number of cases processed. It can be computed with: Accuracy = (TP + TN) / (TP + TN + FP + FN) Where: TP: True positive TN: True negative FP: False positive FN: False negative.\n","\n","Accuracy is a common evaluation metric used to measure the accuracy of a classification model. So it is suitable for our case in binary classification for toxic and non-toxic comments.\n","\n","We then make a compute_metrics function to be used later in the evaluation of the model. As a parameter, we pass the model's predictions (eval_pred). The function extracts the predicted labels, compares them to the true labels (references), and calculates the accuracy using the loaded accuracy metric. The final accuracy value is then returned. This function encapsulates the logic for computing accuracy during the evaluation phase and will bes used in a later step in the model trainer."]},{"cell_type":"markdown","metadata":{},"source":["## Making the model"]},{"cell_type":"markdown","metadata":{},"source":["\n","## Conclusion"]},{"cell_type":"markdown","metadata":{},"source":["### Making the model"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-12-12T14:11:36.401991Z","iopub.status.busy":"2023-12-12T14:11:36.401627Z","iopub.status.idle":"2023-12-12T14:11:37.031853Z","shell.execute_reply":"2023-12-12T14:11:37.031097Z","shell.execute_reply.started":"2023-12-12T14:11:36.401964Z"},"id":"xyx9DB6-ZhLQ","outputId":"921b583b-6cf1-4761-8c78-02f5ce72ed9d","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Download the pre-trained model\n","model = AutoModelForSequenceClassification.from_pretrained(pretrained_model, num_labels=2, id2label=id2label, label2id=label2id, output_attentions=True)"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T14:11:59.729121Z","iopub.status.busy":"2023-12-12T14:11:59.728721Z","iopub.status.idle":"2023-12-12T14:11:59.841341Z","shell.execute_reply":"2023-12-12T14:11:59.840301Z","shell.execute_reply.started":"2023-12-12T14:11:59.729080Z"},"id":"-ygf7Nahgbwk","trusted":true},"outputs":[],"source":["# Defining the training arguements\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    learning_rate=2e-5,\n","    warmup_ratio=0.1,\n","    lr_scheduler_type=\"cosine\",\n","    fp16=True,\n","    num_train_epochs=2,\n","    weight_decay=0.01,\n",")"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.execute_input":"2023-12-12T14:12:25.733179Z","iopub.status.busy":"2023-12-12T14:12:25.732775Z","iopub.status.idle":"2023-12-12T14:15:04.091552Z","shell.execute_reply":"2023-12-12T14:15:04.090391Z","shell.execute_reply.started":"2023-12-12T14:12:25.733147Z"},"id":"9tN3brjKSfxY","outputId":"1cd24289-485d-4465-aedf-d1aee4a291e3","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["Tracking run with wandb version 0.16.1"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20231212_141246-hq9emzmu</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/dina_team_6/huggingface/runs/hq9emzmu' target=\"_blank\">splendid-dawn-4</a></strong> to <a href='https://wandb.ai/dina_team_6/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/dina_team_6/huggingface' target=\"_blank\">https://wandb.ai/dina_team_6/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/dina_team_6/huggingface/runs/hq9emzmu' target=\"_blank\">https://wandb.ai/dina_team_6/huggingface/runs/hq9emzmu</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='350' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [350/350 01:39, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=350, training_loss=0.2803288922991071, metrics={'train_runtime': 150.4657, 'train_samples_per_second': 37.218, 'train_steps_per_second': 2.326, 'total_flos': 741817432473600.0, 'train_loss': 0.2803288922991071, 'epoch': 2.0})"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["# Training the model on our data with our specific training arguements\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tok_train_dataset,\n","    eval_dataset=tok_test_dataset,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T14:15:29.675718Z","iopub.status.busy":"2023-12-12T14:15:29.675321Z","iopub.status.idle":"2023-12-12T14:15:30.149245Z","shell.execute_reply":"2023-12-12T14:15:30.148079Z","shell.execute_reply.started":"2023-12-12T14:15:29.675685Z"},"trusted":true},"outputs":[],"source":["# Saving the trained model along with other training-related information\n","trainer.save_model(\"comments_model\")"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T14:15:41.220670Z","iopub.status.busy":"2023-12-12T14:15:41.220002Z","iopub.status.idle":"2023-12-12T14:15:41.828482Z","shell.execute_reply":"2023-12-12T14:15:41.827350Z","shell.execute_reply.started":"2023-12-12T14:15:41.220636Z"},"trusted":true},"outputs":[],"source":["# Saving the raw model object as is, without any additional information related to training\n","# We will use this for prediction\n","model_save_path = '/kaggle/working/comments_model.pkl'\n","\n","with open(model_save_path, 'wb') as model_file:\n","    pickle.dump(model, model_file)"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T14:15:51.456721Z","iopub.status.busy":"2023-12-12T14:15:51.456321Z","iopub.status.idle":"2023-12-12T14:15:51.829038Z","shell.execute_reply":"2023-12-12T14:15:51.827767Z","shell.execute_reply.started":"2023-12-12T14:15:51.456688Z"},"trusted":true},"outputs":[],"source":["# Loading the raw model\n","model_pickle_path = '/kaggle/working/comments_model.pkl'\n","\n","with open(model_pickle_path, 'rb') as model_file:\n","    model = pickle.load(model_file)"]},{"cell_type":"markdown","metadata":{},"source":["### Testing the model"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T14:18:51.637297Z","iopub.status.busy":"2023-12-12T14:18:51.636772Z","iopub.status.idle":"2023-12-12T14:18:52.331914Z","shell.execute_reply":"2023-12-12T14:18:52.330792Z","shell.execute_reply.started":"2023-12-12T14:18:51.637248Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[{'label': 'Not Toxic', 'score': 0.7726908326148987}]\n","[{'label': 'Toxic', 'score': 0.9823653101921082}]\n"]}],"source":["# Load the pre-trained tokenizer and model\n","model_path = \"/kaggle/working/comments_model\"\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","model = AutoModelForSequenceClassification.from_pretrained(model_path)\n"," \n","# Create a text classification pipeline using the loaded model and tokenizer\n","pipeline =  TextClassificationPipeline(model=model, tokenizer=tokenizer)\n","\n","# Make predictions on sample texts and print the results\n","print(pipeline(\"You are beautiful\"))\n","print(pipeline(\"You are ugly\"))"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2023-12-12T14:19:02.556218Z","iopub.status.busy":"2023-12-12T14:19:02.555306Z","iopub.status.idle":"2023-12-12T14:19:02.566176Z","shell.execute_reply":"2023-12-12T14:19:02.565124Z","shell.execute_reply.started":"2023-12-12T14:19:02.556184Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'_name_or_path': 'distilbert-base-cased',\n"," 'activation': 'gelu',\n"," 'architectures': ['DistilBertForSequenceClassification'],\n"," 'attention_dropout': 0.1,\n"," 'dim': 768,\n"," 'dropout': 0.1,\n"," 'hidden_dim': 3072,\n"," 'id2label': {'0': 'Not Toxic', '1': 'Toxic'},\n"," 'initializer_range': 0.02,\n"," 'label2id': {'Not Toxic': 0, 'Toxic': 1},\n"," 'max_position_embeddings': 512,\n"," 'model_type': 'distilbert',\n"," 'n_heads': 12,\n"," 'n_layers': 6,\n"," 'output_attentions': True,\n"," 'output_past': True,\n"," 'pad_token_id': 0,\n"," 'problem_type': 'single_label_classification',\n"," 'qa_dropout': 0.1,\n"," 'seq_classif_dropout': 0.2,\n"," 'sinusoidal_pos_embds': False,\n"," 'tie_weights_': True,\n"," 'torch_dtype': 'float32',\n"," 'transformers_version': '4.29.2',\n"," 'vocab_size': 28996}"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["# For extra insight, we look at the json file\n","import json\n","\n","config_path = \"/kaggle/working/comments_model/config.json\"\n","\n","with open(config_path, 'r') as config_file:\n","    config = json.load(config_file)\n","\n","config\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4151559,"sourceId":7182320,"sourceType":"datasetVersion"}],"dockerImageVersionId":30616,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"08b81f61b85c47449781b01740371de3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1298db08f0154838bbef3ff6b68514e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30d05b5ca79b437ea0c4b07c12ec81ca","placeholder":"​","style":"IPY_MODEL_9adeccff48bd4171bc4dbfadf7e86371","value":" 159571/159571 [03:56&lt;00:00, 745.58 examples/s]"}},"14a5b890a9cc4ee6999df60d9c53be70":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30d05b5ca79b437ea0c4b07c12ec81ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b9e8d8732254002a3c1c5719d418132":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eda5a85740aa4cbe82a4f003d76ddb65","max":159571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_730e5d4b30e44e8a936296240ad87f12","value":159571}},"730e5d4b30e44e8a936296240ad87f12":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"91460ce95f56438dae180b72003d7b60":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9adeccff48bd4171bc4dbfadf7e86371":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9d53553da52458db77a4a32d9009f38":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91460ce95f56438dae180b72003d7b60","placeholder":"​","style":"IPY_MODEL_14a5b890a9cc4ee6999df60d9c53be70","value":"Map: 100%"}},"eda5a85740aa4cbe82a4f003d76ddb65":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef6c3ec157194946908db760941f9bb8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b9d53553da52458db77a4a32d9009f38","IPY_MODEL_3b9e8d8732254002a3c1c5719d418132","IPY_MODEL_1298db08f0154838bbef3ff6b68514e5"],"layout":"IPY_MODEL_08b81f61b85c47449781b01740371de3"}}}}},"nbformat":4,"nbformat_minor":4}
